[
  {
    "role": "user",
    "content": [
      {
        "type": "text",
        "text": "Explain the concept illustrated in this image"
      },
      {
        "type": "image",
        "image": "https://qgame3ccfcbtygae.public.blob.vercel-storage.com/Transformer,_full_architecture-OWwPJYgyXjblaGxb75bNFvxaUpqAKv.png"
      }
    ]
  },
  {
    "role": "assistant",
    "content": "This image shows the architecture of a transformer model, comparing the encoder (left) and decoder (right) components.  What would you like to know about the specifics of each component?\n"
  },
  { "role": "user", "content": "Explain the architecture in detail" },
  {
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "The encoder uses self-attention and a feed-forward network, while the decoder uses masked self-attention, cross-attention, and a feed-forward network.  Do you want more details about a specific component?\n"
      }
    ]
  }
]

// "react": "19.0.0-rc-7771d3a7-20240827",
// "react-dom": "19.0.0-rc-7771d3a7-20240827",
